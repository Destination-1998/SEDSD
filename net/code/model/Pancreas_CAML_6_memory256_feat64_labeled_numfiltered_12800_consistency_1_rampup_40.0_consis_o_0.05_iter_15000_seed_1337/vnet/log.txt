[16:21:19.929] Namespace(dataset_name='Pancreas', root_path='D:\\lixin\\data/Pancreas', exp='CAML', model='vnet', max_iteration=15000, max_samples=61, labeled_bs=2, batch_size=4, base_lr=0.01, deterministic=0, labelnum=6, seed=1337, gpu='0', lamda=1, consistency=1, consistency_o=0.05, consistency_rampup=40.0, temperature=0.1, memory_num=256, embedding_dim=64, num_filtered=12800, kd_T=3)
[16:21:20.223] 3 itertations per epoch
[16:21:23.071] iteration 1 : loss : 1.937931, loss_s: 3.875133, loss_c: 0.102686
[16:21:24.168] iteration 2 : loss : 1.849132, loss_s: 3.697546, loss_c: 0.101018
[16:21:25.262] iteration 3 : loss : 1.824535, loss_s: 3.648653, loss_c: 0.056478
[16:21:26.379] iteration 4 : loss : 1.798809, loss_s: 3.596912, loss_c: 0.099182
[16:21:27.361] iteration 5 : loss : 1.880375, loss_s: 3.760286, loss_c: 0.063121
[16:21:28.431] iteration 6 : loss : 1.801892, loss_s: 3.602903, loss_c: 0.125101
[16:21:29.571] iteration 7 : loss : 1.865779, loss_s: 3.730808, loss_c: 0.105826
[16:21:30.579] iteration 8 : loss : 1.883922, loss_s: 3.767170, loss_c: 0.094547
[16:21:31.623] iteration 9 : loss : 1.830126, loss_s: 3.659785, loss_c: 0.063859
[16:21:32.609] iteration 10 : loss : 1.843422, loss_s: 3.686276, loss_c: 0.078722
[16:21:33.686] iteration 11 : loss : 1.825925, loss_s: 3.650856, loss_c: 0.142051
[16:21:34.767] iteration 12 : loss : 1.780771, loss_s: 3.560630, loss_c: 0.129986
[16:21:35.852] iteration 13 : loss : 1.960324, loss_s: 3.920150, loss_c: 0.068589
[16:21:36.888] iteration 14 : loss : 1.881357, loss_s: 3.762146, loss_c: 0.078769
[16:21:38.114] iteration 15 : loss : 1.877196, loss_s: 3.753750, loss_c: 0.089582
[16:21:39.055] iteration 16 : loss : 1.828663, loss_s: 3.656878, loss_c: 0.060941
[16:21:40.053] iteration 17 : loss : 1.760201, loss_s: 3.519627, loss_c: 0.109622
[16:21:41.053] iteration 18 : loss : 1.853733, loss_s: 3.706914, loss_c: 0.076552
[16:21:42.053] iteration 19 : loss : 1.816082, loss_s: 3.631633, loss_c: 0.073209
[16:21:43.129] iteration 20 : loss : 1.973906, loss_s: 3.947247, loss_c: 0.078471
[16:21:44.124] iteration 21 : loss : 1.719650, loss_s: 3.438773, loss_c: 0.072631
[16:21:45.156] iteration 22 : loss : 1.825332, loss_s: 3.650061, loss_c: 0.083989
[16:21:46.250] iteration 23 : loss : 1.739124, loss_s: 3.477660, loss_c: 0.082007
[16:21:47.362] iteration 24 : loss : 1.750384, loss_s: 3.500077, loss_c: 0.096988
[16:21:48.351] iteration 25 : loss : 1.893544, loss_s: 3.786471, loss_c: 0.086268
[16:21:49.387] iteration 26 : loss : 1.723466, loss_s: 3.446559, loss_c: 0.050313
[16:21:50.479] iteration 27 : loss : 1.947148, loss_s: 3.893767, loss_c: 0.073449
[16:21:51.594] iteration 28 : loss : 1.751054, loss_s: 3.501515, loss_c: 0.082553
[16:21:52.660] iteration 29 : loss : 1.880751, loss_s: 3.761196, loss_c: 0.040345
[16:21:53.732] iteration 30 : loss : 1.959771, loss_s: 3.919169, loss_c: 0.050011
[16:21:54.804] iteration 31 : loss : 1.769855, loss_s: 3.539399, loss_c: 0.040875
[16:21:55.826] iteration 32 : loss : 1.772783, loss_s: 3.544879, loss_c: 0.096786
[16:21:56.869] iteration 33 : loss : 1.812059, loss_s: 3.623704, loss_c: 0.056400
[16:21:57.917] iteration 34 : loss : 1.753608, loss_s: 3.506880, loss_c: 0.044779
[16:21:58.890] iteration 35 : loss : 1.821772, loss_s: 3.642948, loss_c: 0.083233
[16:21:59.880] iteration 36 : loss : 1.808106, loss_s: 3.615761, loss_c: 0.061975
[16:22:00.929] iteration 37 : loss : 1.757554, loss_s: 3.514744, loss_c: 0.048878
[16:22:02.053] iteration 38 : loss : 1.711375, loss_s: 3.422190, loss_c: 0.078304
[16:22:03.170] iteration 39 : loss : 1.750398, loss_s: 3.500484, loss_c: 0.041015
[16:22:04.197] iteration 40 : loss : 1.916352, loss_s: 3.832377, loss_c: 0.044112
[16:22:05.269] iteration 41 : loss : 1.840558, loss_s: 3.680643, loss_c: 0.065197
[16:22:06.250] iteration 42 : loss : 1.696912, loss_s: 3.393499, loss_c: 0.043124
[16:22:07.317] iteration 43 : loss : 1.769895, loss_s: 3.539368, loss_c: 0.058169
[16:22:08.357] iteration 44 : loss : 1.786382, loss_s: 3.572400, loss_c: 0.048903
[16:22:09.390] iteration 45 : loss : 1.796477, loss_s: 3.592713, loss_c: 0.030864
[16:22:10.480] iteration 46 : loss : 1.834450, loss_s: 3.668283, loss_c: 0.086838
[16:22:11.653] iteration 47 : loss : 1.774524, loss_s: 3.548718, loss_c: 0.044062
[16:22:12.724] iteration 48 : loss : 1.910877, loss_s: 3.821264, loss_c: 0.068043
[16:22:13.873] iteration 49 : loss : 1.725861, loss_s: 3.451446, loss_c: 0.036041
[16:22:15.061] iteration 50 : loss : 1.754679, loss_s: 3.508579, loss_c: 0.110857
[16:22:16.212] iteration 51 : loss : 1.731047, loss_s: 3.461521, loss_c: 0.079769
[16:22:17.282] iteration 52 : loss : 1.697140, loss_s: 3.394041, loss_c: 0.031162
[16:22:18.302] iteration 53 : loss : 1.784731, loss_s: 3.568821, loss_c: 0.090060
[16:22:19.272] iteration 54 : loss : 1.833966, loss_s: 3.667326, loss_c: 0.085513
[16:22:20.379] iteration 55 : loss : 1.895364, loss_s: 3.790219, loss_c: 0.070690
[16:22:21.426] iteration 56 : loss : 1.711302, loss_s: 3.422057, loss_c: 0.076061
[16:22:22.423] iteration 57 : loss : 1.987658, loss_s: 3.974930, loss_c: 0.052365
[16:22:23.573] iteration 58 : loss : 1.890206, loss_s: 3.779992, loss_c: 0.057589
[16:22:24.567] iteration 59 : loss : 1.670020, loss_s: 3.339114, loss_c: 0.132505
[16:22:25.643] iteration 60 : loss : 1.899598, loss_s: 3.798945, loss_c: 0.032813
[16:22:26.677] iteration 61 : loss : 1.791023, loss_s: 3.581855, loss_c: 0.023966
[16:22:27.681] iteration 62 : loss : 1.771618, loss_s: 3.542662, loss_c: 0.080346
[16:22:28.718] iteration 63 : loss : 1.712385, loss_s: 3.424433, loss_c: 0.045541
[16:22:29.639] iteration 64 : loss : 1.775619, loss_s: 3.550187, loss_c: 0.151231
[16:22:30.670] iteration 65 : loss : 1.854148, loss_s: 3.707892, loss_c: 0.054921
[16:22:31.721] iteration 66 : loss : 1.812088, loss_s: 3.623917, loss_c: 0.034414
[16:22:32.823] iteration 67 : loss : 1.697595, loss_s: 3.394865, loss_c: 0.043419
[16:22:33.762] iteration 68 : loss : 1.855040, loss_s: 3.709350, loss_c: 0.103527
[16:22:34.728] iteration 69 : loss : 1.911704, loss_s: 3.823227, loss_c: 0.022444
[16:22:35.722] iteration 70 : loss : 1.755496, loss_s: 3.510810, loss_c: 0.022463
[16:22:36.806] iteration 71 : loss : 1.784043, loss_s: 3.567442, loss_c: 0.090846
[16:22:37.759] iteration 72 : loss : 1.719085, loss_s: 3.437912, loss_c: 0.033502
[16:22:38.750] iteration 73 : loss : 1.864007, loss_s: 3.727777, loss_c: 0.030976
[16:22:39.692] iteration 74 : loss : 1.752913, loss_s: 3.505396, loss_c: 0.059100
[16:22:40.721] iteration 75 : loss : 1.632768, loss_s: 3.265017, loss_c: 0.072787
[16:22:41.643] iteration 76 : loss : 1.764115, loss_s: 3.526796, loss_c: 0.207891
[16:22:42.575] iteration 77 : loss : 1.862778, loss_s: 3.725358, loss_c: 0.025362
[16:22:43.560] iteration 78 : loss : 1.864830, loss_s: 3.729441, loss_c: 0.028015
[16:22:44.524] iteration 79 : loss : 1.810947, loss_s: 3.621334, loss_c: 0.078231
[16:22:45.476] iteration 80 : loss : 1.908026, loss_s: 3.815689, loss_c: 0.049199
[16:22:46.486] iteration 81 : loss : 1.762416, loss_s: 3.524403, loss_c: 0.059172
[16:22:47.493] iteration 82 : loss : 1.967308, loss_s: 3.934323, loss_c: 0.039206
[16:22:48.496] iteration 83 : loss : 1.620377, loss_s: 3.240453, loss_c: 0.039617
[16:22:49.417] iteration 84 : loss : 1.699807, loss_s: 3.399151, loss_c: 0.063966
[16:22:50.442] iteration 85 : loss : 1.714452, loss_s: 3.428612, loss_c: 0.039504
[16:22:51.357] iteration 86 : loss : 1.764810, loss_s: 3.529248, loss_c: 0.050007
[16:22:52.229] iteration 87 : loss : 1.856754, loss_s: 3.712912, loss_c: 0.083782
[16:22:53.116] iteration 88 : loss : 1.757321, loss_s: 3.514426, loss_c: 0.027666
[16:22:54.048] iteration 89 : loss : 1.862897, loss_s: 3.725465, loss_c: 0.044532
[16:22:55.043] iteration 90 : loss : 1.803146, loss_s: 3.605683, loss_c: 0.085929
[16:22:55.923] iteration 91 : loss : 1.724805, loss_s: 3.449190, loss_c: 0.057561
[16:22:56.927] iteration 92 : loss : 1.864608, loss_s: 3.728893, loss_c: 0.043355
[16:22:57.896] iteration 93 : loss : 1.597966, loss_s: 3.195323, loss_c: 0.085788
[16:22:58.849] iteration 94 : loss : 1.860930, loss_s: 3.721369, loss_c: 0.068308
[16:22:59.667] iteration 95 : loss : 1.844025, loss_s: 3.687597, loss_c: 0.063153
[16:23:00.635] iteration 96 : loss : 1.580168, loss_s: 3.160060, loss_c: 0.036336
[16:23:01.530] iteration 97 : loss : 1.979436, loss_s: 3.958054, loss_c: 0.116681
[16:23:02.422] iteration 98 : loss : 1.740832, loss_s: 3.481330, loss_c: 0.044973
[16:23:03.355] iteration 99 : loss : 1.492068, loss_s: 2.983890, loss_c: 0.031777
[16:23:04.205] iteration 100 : loss : 1.737673, loss_s: 3.474889, loss_c: 0.063418
[16:23:05.086] iteration 101 : loss : 1.719236, loss_s: 3.438075, loss_c: 0.054028
[16:23:06.013] iteration 102 : loss : 1.688720, loss_s: 3.377064, loss_c: 0.051187
[16:23:06.980] iteration 103 : loss : 1.719535, loss_s: 3.438629, loss_c: 0.061591
[16:23:07.864] iteration 104 : loss : 1.722396, loss_s: 3.444128, loss_c: 0.093714
[16:23:08.870] iteration 105 : loss : 1.962074, loss_s: 3.923770, loss_c: 0.051311
[16:23:09.826] iteration 106 : loss : 1.733809, loss_s: 3.467058, loss_c: 0.078591
[16:23:10.768] iteration 107 : loss : 1.991902, loss_s: 3.983444, loss_c: 0.049080
[16:23:11.729] iteration 108 : loss : 1.573134, loss_s: 3.145826, loss_c: 0.061482
[16:23:12.605] iteration 109 : loss : 1.797525, loss_s: 3.594653, loss_c: 0.054365
[16:23:13.623] iteration 110 : loss : 1.835681, loss_s: 3.671042, loss_c: 0.043540
[16:23:14.575] iteration 111 : loss : 1.687317, loss_s: 3.374260, loss_c: 0.051224
[16:23:15.530] iteration 112 : loss : 1.647185, loss_s: 3.293977, loss_c: 0.054303
[16:23:16.392] iteration 113 : loss : 1.671621, loss_s: 3.343029, loss_c: 0.027596
[16:23:17.329] iteration 114 : loss : 1.666220, loss_s: 3.332044, loss_c: 0.054396
[16:23:18.168] iteration 115 : loss : 1.725437, loss_s: 3.450604, loss_c: 0.035336
[16:23:19.141] iteration 116 : loss : 1.783352, loss_s: 3.566304, loss_c: 0.055598
[16:23:20.040] iteration 117 : loss : 1.756056, loss_s: 3.511774, loss_c: 0.046270
[16:23:21.027] iteration 118 : loss : 1.681370, loss_s: 3.362453, loss_c: 0.038371
[16:23:22.020] iteration 119 : loss : 1.893842, loss_s: 3.787277, loss_c: 0.056389
[16:23:22.843] iteration 120 : loss : 1.777926, loss_s: 3.555543, loss_c: 0.041981
[16:23:23.729] iteration 121 : loss : 1.794670, loss_s: 3.589043, loss_c: 0.040506
[16:23:24.715] iteration 122 : loss : 1.548775, loss_s: 3.097011, loss_c: 0.075616
[16:23:25.648] iteration 123 : loss : 1.833322, loss_s: 3.666082, loss_c: 0.078809
[16:23:26.560] iteration 124 : loss : 1.674794, loss_s: 3.349353, loss_c: 0.031007
[16:23:27.500] iteration 125 : loss : 1.876833, loss_s: 3.753232, loss_c: 0.060363
[16:23:28.405] iteration 126 : loss : 1.664251, loss_s: 3.327650, loss_c: 0.122286
[16:23:29.430] iteration 127 : loss : 1.770467, loss_s: 3.540399, loss_c: 0.075096
[16:23:30.378] iteration 128 : loss : 1.823965, loss_s: 3.647578, loss_c: 0.048208
[16:23:31.376] iteration 129 : loss : 1.797081, loss_s: 3.593792, loss_c: 0.050722
[16:23:32.333] iteration 130 : loss : 1.433821, loss_s: 2.866989, loss_c: 0.092683
[16:23:33.205] iteration 131 : loss : 1.628755, loss_s: 3.257109, loss_c: 0.055039
[16:23:34.133] iteration 132 : loss : 1.773172, loss_s: 3.545868, loss_c: 0.066631
[16:23:35.133] iteration 133 : loss : 1.603301, loss_s: 3.206021, loss_c: 0.081654
[16:23:36.028] iteration 134 : loss : 1.837859, loss_s: 3.675490, loss_c: 0.029984
[16:23:37.120] iteration 135 : loss : 1.795149, loss_s: 3.589813, loss_c: 0.067339
[16:23:37.981] iteration 136 : loss : 1.839697, loss_s: 3.678708, loss_c: 0.097995
[16:23:38.920] iteration 137 : loss : 1.646426, loss_s: 3.292581, loss_c: 0.035814
[16:23:39.865] iteration 138 : loss : 1.691794, loss_s: 3.383273, loss_c: 0.043559
[16:23:40.763] iteration 139 : loss : 1.876320, loss_s: 3.751945, loss_c: 0.098700
[16:23:41.669] iteration 140 : loss : 1.822456, loss_s: 3.644583, loss_c: 0.044290
[16:23:42.603] iteration 141 : loss : 1.811369, loss_s: 3.622379, loss_c: 0.049185
[16:23:43.550] iteration 142 : loss : 1.589115, loss_s: 3.177887, loss_c: 0.046802
[16:23:44.496] iteration 143 : loss : 1.781974, loss_s: 3.563554, loss_c: 0.053591
[16:23:45.405] iteration 144 : loss : 1.432473, loss_s: 2.864521, loss_c: 0.059021
[16:23:46.388] iteration 145 : loss : 1.788717, loss_s: 3.576963, loss_c: 0.065456
[16:23:47.329] iteration 146 : loss : 1.596513, loss_s: 3.192639, loss_c: 0.053198
[16:23:48.305] iteration 147 : loss : 1.750983, loss_s: 3.501667, loss_c: 0.039569
[16:23:49.209] iteration 148 : loss : 1.837070, loss_s: 3.673779, loss_c: 0.049637
[16:23:50.107] iteration 149 : loss : 1.555886, loss_s: 3.111316, loss_c: 0.063372
[16:23:51.060] iteration 150 : loss : 1.543517, loss_s: 3.085486, loss_c: 0.175330
[16:23:52.047] iteration 151 : loss : 1.549658, loss_s: 3.098775, loss_c: 0.058438
[16:23:52.981] iteration 152 : loss : 1.816730, loss_s: 3.632443, loss_c: 0.114191
[16:23:54.006] iteration 153 : loss : 1.694147, loss_s: 3.387954, loss_c: 0.035262
[16:23:55.026] iteration 154 : loss : 1.755914, loss_s: 3.511423, loss_c: 0.042474
[16:23:55.888] iteration 155 : loss : 1.728872, loss_s: 3.457365, loss_c: 0.039828
[16:23:56.778] iteration 156 : loss : 1.461929, loss_s: 2.923204, loss_c: 0.071616
[16:23:57.731] iteration 157 : loss : 1.759416, loss_s: 3.517538, loss_c: 0.146349
[16:23:58.608] iteration 158 : loss : 1.456784, loss_s: 2.913104, loss_c: 0.049575
[16:23:59.414] iteration 159 : loss : 1.661043, loss_s: 3.321676, loss_c: 0.043348
[16:24:00.308] iteration 160 : loss : 1.746800, loss_s: 3.492751, loss_c: 0.093750
[16:24:01.167] iteration 161 : loss : 1.582471, loss_s: 3.164632, loss_c: 0.031890
[16:24:02.223] iteration 162 : loss : 1.428233, loss_s: 2.855966, loss_c: 0.053739
[16:24:03.184] iteration 163 : loss : 1.647736, loss_s: 3.295047, loss_c: 0.044804
[16:24:04.231] iteration 164 : loss : 1.726681, loss_s: 3.451674, loss_c: 0.191636
[16:24:05.173] iteration 165 : loss : 1.767618, loss_s: 3.534715, loss_c: 0.056120
[16:24:06.046] iteration 166 : loss : 1.676623, loss_s: 3.352376, loss_c: 0.096976
[16:24:06.897] iteration 167 : loss : 1.504833, loss_s: 3.009170, loss_c: 0.053261
[16:24:07.768] iteration 168 : loss : 1.870348, loss_s: 3.740051, loss_c: 0.070413
[16:24:08.619] iteration 169 : loss : 1.649836, loss_s: 3.299031, loss_c: 0.070284
[16:24:09.481] iteration 170 : loss : 1.541319, loss_s: 3.082134, loss_c: 0.054399
[16:24:10.400] iteration 171 : loss : 1.648432, loss_s: 3.296428, loss_c: 0.046760
[16:24:11.324] iteration 172 : loss : 1.732055, loss_s: 3.463334, loss_c: 0.086285
[16:24:12.159] iteration 173 : loss : 1.490672, loss_s: 2.980775, loss_c: 0.062394
[16:24:13.100] iteration 174 : loss : 1.900597, loss_s: 3.800956, loss_c: 0.024114
[16:24:13.972] iteration 175 : loss : 1.411363, loss_s: 2.822340, loss_c: 0.040938
[16:24:14.963] iteration 176 : loss : 1.711250, loss_s: 3.421768, loss_c: 0.080655
[16:24:15.936] iteration 177 : loss : 1.719530, loss_s: 3.438545, loss_c: 0.055877
[16:24:16.806] iteration 178 : loss : 1.768551, loss_s: 3.536503, loss_c: 0.065995
[16:24:17.717] iteration 179 : loss : 1.522174, loss_s: 3.043489, loss_c: 0.095379
[16:24:18.632] iteration 180 : loss : 1.938674, loss_s: 3.876577, loss_c: 0.085026
[16:24:19.499] iteration 181 : loss : 1.571022, loss_s: 3.140774, loss_c: 0.143312
[16:24:20.358] iteration 182 : loss : 1.624809, loss_s: 3.248666, loss_c: 0.106174
[16:24:21.334] iteration 183 : loss : 1.837762, loss_s: 3.675011, loss_c: 0.055655
[16:24:22.318] iteration 184 : loss : 1.892848, loss_s: 3.784775, loss_c: 0.102580
[16:24:23.254] iteration 185 : loss : 1.595919, loss_s: 3.191018, loss_c: 0.090969
[16:24:24.103] iteration 186 : loss : 1.742639, loss_s: 3.483826, loss_c: 0.164692
[16:24:24.942] iteration 187 : loss : 1.534393, loss_s: 3.067988, loss_c: 0.087935
[16:24:25.856] iteration 188 : loss : 1.354443, loss_s: 2.708085, loss_c: 0.088837
[16:24:26.718] iteration 189 : loss : 1.818216, loss_s: 3.634558, loss_c: 0.213206
[16:24:27.655] iteration 190 : loss : 1.639934, loss_s: 3.279053, loss_c: 0.089642
[16:24:28.735] iteration 191 : loss : 1.675056, loss_s: 3.349447, loss_c: 0.073455
[16:24:29.758] iteration 192 : loss : 1.460659, loss_s: 2.920698, loss_c: 0.067867
[16:24:30.747] iteration 193 : loss : 1.591230, loss_s: 3.181989, loss_c: 0.050585
[16:24:31.620] iteration 194 : loss : 1.688102, loss_s: 3.375606, loss_c: 0.065174
[16:24:32.548] iteration 195 : loss : 1.733141, loss_s: 3.465384, loss_c: 0.100103
[16:24:33.363] iteration 196 : loss : 1.692892, loss_s: 3.385492, loss_c: 0.030370
[16:24:34.270] iteration 197 : loss : 1.592359, loss_s: 3.184229, loss_c: 0.053129
[16:24:35.274] iteration 198 : loss : 1.483343, loss_s: 2.966362, loss_c: 0.033660
[16:24:36.406] iteration 199 : loss : 1.908150, loss_s: 3.815335, loss_c: 0.109046
[16:24:37.406] iteration 200 : loss : 1.504891, loss_s: 3.009234, loss_c: 0.059448
[16:24:38.281] iteration 201 : loss : 1.777397, loss_s: 3.554186, loss_c: 0.066602
[16:24:39.110] iteration 202 : loss : 1.300096, loss_s: 2.599070, loss_c: 0.127095
[16:24:40.074] iteration 203 : loss : 1.811498, loss_s: 3.622548, loss_c: 0.048302
[16:24:40.963] iteration 204 : loss : 1.398923, loss_s: 2.797442, loss_c: 0.042975
[16:24:41.813] iteration 205 : loss : 1.618142, loss_s: 3.235636, loss_c: 0.070629
[16:24:42.753] iteration 206 : loss : 1.830153, loss_s: 3.660006, loss_c: 0.030793
[16:24:43.687] iteration 207 : loss : 1.481286, loss_s: 2.962006, loss_c: 0.061615
[16:24:44.634] iteration 208 : loss : 1.768279, loss_s: 3.535888, loss_c: 0.074195
[16:24:45.512] iteration 209 : loss : 1.331615, loss_s: 2.662363, loss_c: 0.096310
[16:24:46.339] iteration 210 : loss : 1.820294, loss_s: 3.640140, loss_c: 0.047603
[16:24:47.196] iteration 211 : loss : 1.741228, loss_s: 3.482036, loss_c: 0.044618
[16:24:48.061] iteration 212 : loss : 1.449677, loss_s: 2.898930, loss_c: 0.044891
[16:24:48.898] iteration 213 : loss : 1.542194, loss_s: 3.083856, loss_c: 0.057215
[16:24:49.810] iteration 214 : loss : 1.654913, loss_s: 3.309337, loss_c: 0.052534
[16:24:50.632] iteration 215 : loss : 1.437327, loss_s: 2.874048, loss_c: 0.065736
[16:24:51.578] iteration 216 : loss : 1.458335, loss_s: 2.916371, loss_c: 0.030051
[16:24:52.457] iteration 217 : loss : 1.574542, loss_s: 3.148466, loss_c: 0.067269
[16:24:53.325] iteration 218 : loss : 1.776482, loss_s: 3.551795, loss_c: 0.131800
[16:24:54.185] iteration 219 : loss : 1.111785, loss_s: 2.222995, loss_c: 0.062567
[16:24:55.136] iteration 220 : loss : 1.522310, loss_s: 3.044179, loss_c: 0.046872
[16:24:56.029] iteration 221 : loss : 1.825610, loss_s: 3.650753, loss_c: 0.050748
[16:24:56.939] iteration 222 : loss : 1.638141, loss_s: 3.275954, loss_c: 0.034645
[16:24:57.910] iteration 223 : loss : 1.452450, loss_s: 2.904325, loss_c: 0.063142
[16:24:58.849] iteration 224 : loss : 1.477606, loss_s: 2.954847, loss_c: 0.039169
[16:24:59.824] iteration 225 : loss : 1.544707, loss_s: 3.089233, loss_c: 0.017593
[16:25:00.734] iteration 226 : loss : 1.554518, loss_s: 3.108558, loss_c: 0.051808
[16:25:01.723] iteration 227 : loss : 1.644620, loss_s: 3.288484, loss_c: 0.084111
[16:25:02.647] iteration 228 : loss : 1.510697, loss_s: 3.020207, loss_c: 0.133998
[16:25:03.650] iteration 229 : loss : 1.483116, loss_s: 2.965819, loss_c: 0.044269
[16:25:04.578] iteration 230 : loss : 1.249172, loss_s: 2.497968, loss_c: 0.039927
[16:25:05.608] iteration 231 : loss : 1.534799, loss_s: 3.069191, loss_c: 0.043751
[16:25:06.557] iteration 232 : loss : 1.775274, loss_s: 3.549274, loss_c: 0.144036
[16:25:07.394] iteration 233 : loss : 1.705714, loss_s: 3.410581, loss_c: 0.093995
[16:25:08.382] iteration 234 : loss : 1.253411, loss_s: 2.506069, loss_c: 0.083347
[16:25:09.399] iteration 235 : loss : 1.651304, loss_s: 3.301727, loss_c: 0.097874
[16:25:10.997] iteration 236 : loss : 1.747311, loss_s: 3.493672, loss_c: 0.105502
[16:25:12.071] iteration 237 : loss : 1.433883, loss_s: 2.866864, loss_c: 0.100523
[16:25:13.079] iteration 238 : loss : 1.599531, loss_s: 3.198121, loss_c: 0.104750
[16:25:14.032] iteration 239 : loss : 1.402366, loss_s: 2.804004, loss_c: 0.080018
[16:25:15.011] iteration 240 : loss : 1.482303, loss_s: 2.964261, loss_c: 0.036211
[16:25:15.980] iteration 241 : loss : 1.680198, loss_s: 3.360036, loss_c: 0.037591
[16:25:16.962] iteration 242 : loss : 1.546381, loss_s: 3.092228, loss_c: 0.057973
[16:25:18.000] iteration 243 : loss : 1.728678, loss_s: 3.456791, loss_c: 0.061376
[16:25:18.985] iteration 244 : loss : 1.516830, loss_s: 3.032801, loss_c: 0.095666
[16:25:19.917] iteration 245 : loss : 1.455242, loss_s: 2.909801, loss_c: 0.075015
[16:25:20.971] iteration 246 : loss : 1.457594, loss_s: 2.914814, loss_c: 0.039429
[16:25:21.838] iteration 247 : loss : 1.428790, loss_s: 2.856513, loss_c: 0.119729
[16:25:22.854] iteration 248 : loss : 1.768355, loss_s: 3.536362, loss_c: 0.036823
[16:25:23.811] iteration 249 : loss : 1.520451, loss_s: 3.040412, loss_c: 0.052805
[16:25:24.819] iteration 250 : loss : 1.767307, loss_s: 3.534266, loss_c: 0.036468
[16:25:25.716] iteration 251 : loss : 1.800610, loss_s: 3.600329, loss_c: 0.099191
[16:25:26.619] iteration 252 : loss : 1.308401, loss_s: 2.616541, loss_c: 0.026108
[16:25:27.496] iteration 253 : loss : 1.600217, loss_s: 3.199916, loss_c: 0.056122
[16:25:28.407] iteration 254 : loss : 1.152272, loss_s: 2.304145, loss_c: 0.042291
[16:25:29.376] iteration 255 : loss : 1.553731, loss_s: 3.107150, loss_c: 0.032527
[16:25:30.380] iteration 256 : loss : 1.143090, loss_s: 2.285429, loss_c: 0.082920
[16:25:31.357] iteration 257 : loss : 1.578851, loss_s: 3.157313, loss_c: 0.041424
[16:25:32.227] iteration 258 : loss : 1.902497, loss_s: 3.804508, loss_c: 0.051971
[16:25:33.246] iteration 259 : loss : 1.306889, loss_s: 2.612739, loss_c: 0.116273
[16:25:34.157] iteration 260 : loss : 1.362874, loss_s: 2.725326, loss_c: 0.044960
[16:25:35.024] iteration 261 : loss : 1.607682, loss_s: 3.215014, loss_c: 0.036136
[16:25:35.972] iteration 262 : loss : 1.652653, loss_s: 3.304362, loss_c: 0.104871
[16:25:37.072] iteration 263 : loss : 1.231173, loss_s: 2.461570, loss_c: 0.085426
[16:25:37.919] iteration 264 : loss : 1.454650, loss_s: 2.908886, loss_c: 0.043673
[16:25:38.870] iteration 265 : loss : 1.553437, loss_s: 3.106413, loss_c: 0.048938
[16:25:39.810] iteration 266 : loss : 1.395317, loss_s: 2.789309, loss_c: 0.149722
[16:25:40.769] iteration 267 : loss : 1.628922, loss_s: 3.257470, loss_c: 0.038580
[16:25:41.658] iteration 268 : loss : 1.438230, loss_s: 2.875614, loss_c: 0.093515
[16:25:42.565] iteration 269 : loss : 1.306656, loss_s: 2.611877, loss_c: 0.161407
[16:25:43.504] iteration 270 : loss : 1.519176, loss_s: 3.037936, loss_c: 0.043694
[16:25:44.383] iteration 271 : loss : 1.195128, loss_s: 2.389931, loss_c: 0.032889
[16:25:45.355] iteration 272 : loss : 1.244721, loss_s: 2.488857, loss_c: 0.063300
[16:25:46.241] iteration 273 : loss : 1.695424, loss_s: 3.390271, loss_c: 0.062741
[16:25:47.187] iteration 274 : loss : 1.174117, loss_s: 2.347926, loss_c: 0.031176
[16:25:48.081] iteration 275 : loss : 1.465949, loss_s: 2.931515, loss_c: 0.040039
[16:25:49.171] iteration 276 : loss : 1.348927, loss_s: 2.696994, loss_c: 0.095300
[16:25:50.031] iteration 277 : loss : 1.525574, loss_s: 3.050572, loss_c: 0.062409
[16:25:50.976] iteration 278 : loss : 1.517892, loss_s: 3.035217, loss_c: 0.061542
[16:25:51.974] iteration 279 : loss : 1.319900, loss_s: 2.639415, loss_c: 0.039978
[16:25:52.930] iteration 280 : loss : 1.365484, loss_s: 2.730540, loss_c: 0.045661
[16:25:53.825] iteration 281 : loss : 0.983682, loss_s: 1.966591, loss_c: 0.085098
[16:25:54.696] iteration 282 : loss : 1.773317, loss_s: 3.545943, loss_c: 0.075321
[16:25:55.656] iteration 283 : loss : 1.609688, loss_s: 3.219038, loss_c: 0.035072
[16:25:56.573] iteration 284 : loss : 1.663932, loss_s: 3.327242, loss_c: 0.067984
[16:25:57.469] iteration 285 : loss : 1.719423, loss_s: 3.437801, loss_c: 0.116891
[16:25:58.437] iteration 286 : loss : 1.539254, loss_s: 3.077647, loss_c: 0.095684
[16:25:59.535] iteration 287 : loss : 1.975210, loss_s: 3.950155, loss_c: 0.026468
[16:26:00.547] iteration 288 : loss : 1.590549, loss_s: 3.180740, loss_c: 0.037257
[16:26:01.480] iteration 289 : loss : 1.599776, loss_s: 3.198932, loss_c: 0.067765
[16:26:02.387] iteration 290 : loss : 1.434044, loss_s: 2.867792, loss_c: 0.030764
[16:26:03.408] iteration 291 : loss : 1.894268, loss_s: 3.787916, loss_c: 0.068134
[16:26:04.387] iteration 292 : loss : 1.888188, loss_s: 3.775883, loss_c: 0.053816
[16:26:05.412] iteration 293 : loss : 1.568772, loss_s: 3.136810, loss_c: 0.081335
[16:26:06.450] iteration 294 : loss : 1.610966, loss_s: 3.221146, loss_c: 0.087397
[16:26:07.520] iteration 295 : loss : 1.781422, loss_s: 3.561429, loss_c: 0.160298
[16:26:08.471] iteration 296 : loss : 1.110358, loss_s: 2.219462, loss_c: 0.141221
[16:26:09.342] iteration 297 : loss : 1.284681, loss_s: 2.568592, loss_c: 0.085212
[16:26:10.328] iteration 298 : loss : 1.237127, loss_s: 2.473180, loss_c: 0.120328
[16:26:11.285] iteration 299 : loss : 1.383099, loss_s: 2.765555, loss_c: 0.070288
[16:26:12.286] iteration 300 : loss : 1.802639, loss_s: 3.604596, loss_c: 0.058268
[16:26:13.252] iteration 301 : loss : 1.548966, loss_s: 3.097073, loss_c: 0.074156
[16:26:14.251] iteration 302 : loss : 1.010201, loss_s: 2.019160, loss_c: 0.109052
[16:26:15.311] iteration 303 : loss : 1.957341, loss_s: 3.914289, loss_c: 0.032015
[16:26:16.139] iteration 304 : loss : 1.460519, loss_s: 2.920185, loss_c: 0.073760
[16:26:17.219] iteration 305 : loss : 1.326411, loss_s: 2.651599, loss_c: 0.107239
[16:26:18.171] iteration 306 : loss : 1.293549, loss_s: 2.585273, loss_c: 0.162050
[16:26:19.135] iteration 307 : loss : 1.206233, loss_s: 2.411934, loss_c: 0.044492
[16:26:20.185] iteration 308 : loss : 1.559334, loss_s: 3.118247, loss_c: 0.034103
[16:26:21.090] iteration 309 : loss : 1.236595, loss_s: 2.472826, loss_c: 0.029061
[16:26:22.121] iteration 310 : loss : 1.307777, loss_s: 2.614976, loss_c: 0.048368
[16:26:22.961] iteration 311 : loss : 1.017159, loss_s: 2.032840, loss_c: 0.130822
[16:26:23.898] iteration 312 : loss : 1.640683, loss_s: 3.281157, loss_c: 0.015151
[16:26:24.832] iteration 313 : loss : 1.603209, loss_s: 3.205517, loss_c: 0.078187
[16:26:25.757] iteration 314 : loss : 0.888571, loss_s: 1.776652, loss_c: 0.040515
